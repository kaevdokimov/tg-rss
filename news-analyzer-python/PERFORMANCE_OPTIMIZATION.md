# Оптимизация производительности news-analyzer-python

## Проблема
При запуске `run_daily.py` сервер нагружается на 100% и перестает отвечать.

## Реализованные оптимизации

### 1. Параллельная обработка текста
- Для больших объемов данных (>100 новостей) используется `ThreadPoolExecutor` для параллельной обработки
- Количество потоков ограничено до 4 для предотвращения перегрузки
- Для малых объемов используется последовательная обработка (меньше накладных расходов)

### 2. Лимит на количество новостей
- Добавлена переменная окружения `MAX_NEWS_LIMIT` (по умолчанию 1000)
- Если новостей больше лимита, обрабатываются только последние N
- Это предотвращает обработку огромных объемов данных за раз

### 3. Оптимизация кластеризации HDBSCAN
- Добавлен параметр `core_dist_n_jobs` для использования нескольких ядер CPU
- Количество ядер ограничено до 4 для предотвращения перегрузки
- Включен `prediction_data=True` для оптимизации

### 4. Задержки между отправками в Telegram
- Добавлена задержка между отправками сообщений (по умолчанию 0.05 секунды)
- Настраивается через переменную окружения `TELEGRAM_SEND_DELAY`
- Это предотвращает превышение лимитов Telegram API (30 сообщений/сек)

## Рекомендации по настройке

### Переменные окружения

Добавьте в ваш `.env` файл:

```bash
# Лимит на количество новостей для обработки
MAX_NEWS_LIMIT=500

# Задержка между отправками в Telegram (в секундах)
TELEGRAM_SEND_DELAY=0.05
```

### Настройка config.yaml

Для снижения нагрузки на сервер рекомендуется:

#### 1. Уменьшить окно анализа
```yaml
analysis:
  time_window_hours: 12  # Вместо 24 часов
```

#### 2. Использовать только заголовки
```yaml
analysis:
  use_titles_only: true  # Уже включено по умолчанию
```

#### 3. Уменьшить количество признаков для векторизации
```yaml
vectorization:
  max_features: 3000  # Вместо 5000
  min_df: 3  # Вместо 2 (уменьшит словарь)
```

#### 4. Увеличить минимальный размер кластера
```yaml
clustering:
  min_cluster_size: 10  # Вместо 5 (меньше кластеров = быстрее)
  min_samples: 5  # Вместо 3
```

#### 5. Использовать только униграммы (убрать биграммы)
Это требует изменения кода в `vectorizer.py`, но значительно ускорит обработку.

## Дополнительные рекомендации

### 1. Запуск в фоновом режиме с низким приоритетом

Используйте `nice` для снижения приоритета процесса:

```bash
nice -n 19 python run_daily.py
```

### 2. Ограничение использования CPU через cgroups

Если используете systemd, создайте service файл с ограничениями:

```ini
[Service]
CPUQuota=50%
MemoryLimit=2G
```

### 3. Запуск в определенное время

Настройте cron на запуск в нерабочее время:

```cron
0 3 * * * cd /path/to/news-analyzer-python && /path/to/venv/bin/python run_daily.py
```

### 4. Мониторинг ресурсов

Добавьте мониторинг использования CPU и памяти:

```bash
# Запуск с мониторингом
time python run_daily.py
```

### 5. Батчинг для очень больших объемов

Если у вас очень много новостей, можно разбить обработку на батчи:

```python
# Пример (требует изменения кода)
batch_size = 200
for i in range(0, len(news_items), batch_size):
    batch = news_items[i:i+batch_size]
    # Обработка батча
```

## Проверка производительности

После применения оптимизаций проверьте:

1. **Использование CPU**: должно быть < 80% в пике
2. **Время выполнения**: должно быть разумным (< 10 минут для 1000 новостей)
3. **Использование памяти**: должно быть стабильным, без утечек

## Отладка проблем

Если сервер все еще перегружается:

1. Уменьшите `MAX_NEWS_LIMIT` до 200-300
2. Увеличьте `min_cluster_size` до 15-20
3. Уменьшите `max_features` до 2000
4. Увеличьте `time_window_hours` до 6-12 часов
5. Проверьте логи на наличие ошибок

## Контакты

При возникновении проблем проверьте логи в `storage/logs/`.

