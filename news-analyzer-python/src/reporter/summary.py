"""–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ä–µ–∑—é–º–µ –æ—Ç—á–µ—Ç–∞."""

from datetime import datetime
from typing import List, Dict, Any, Optional

from ..utils.logger import get_logger

logger = get_logger(__name__)


class SummaryGenerator:
    """–ö–ª–∞—Å—Å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ä–µ–∑—é–º–µ."""
    
    def generate(
        self,
        narratives: List[Dict[str, Any]],
        total_news: int,
        analysis_date: datetime,
        clustering_metrics: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤–æ–µ —Ä–µ–∑—é–º–µ –æ—Ç—á–µ—Ç–∞.
        
        Args:
            narratives: –°–ø–∏—Å–æ–∫ –Ω–∞—Ä—Ä–∞—Ç–∏–≤–æ–≤
            total_news: –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π
            analysis_date: –î–∞—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –¢–µ–∫—Å—Ç–æ–≤–æ–µ —Ä–µ–∑—é–º–µ
        """
        lines = []
        lines.append("=" * 60)
        lines.append(f"–ö–ê–†–¢–ê –î–ù–Ø - {analysis_date.strftime('%d.%m.%Y')}")
        lines.append("=" * 60)
        lines.append("")
        lines.append(f"–í—Å–µ–≥–æ –Ω–æ–≤–æ—Å—Ç–µ–π: {total_news}")
        lines.append(f"–í—ã—è–≤–ª–µ–Ω–æ —Ç–µ–º: {len(narratives)}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ç–µ–º—ã
        if len(narratives) == 0:
            lines.append("")
            lines.append("‚ö†Ô∏è –¢–µ–º—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            lines.append("‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ")
            lines.append("–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π")
            lines.append("")
            lines.append("=" * 60)
            return "\n".join(lines)

        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
        if clustering_metrics:
            lines.append(f"üìä –ú–µ—Ç—Ä–∏–∫–∏ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏:")
            lines.append(f"   ‚Ä¢ –ö–ª–∞—Å—Ç–µ—Ä–æ–≤: {clustering_metrics.get('total_clusters', 0)}")
            lines.append(f"   ‚Ä¢ –®—É–º–æ–≤—ã—Ö —Ç–æ—á–µ–∫: {clustering_metrics.get('noise_points', 0)} ({clustering_metrics.get('noise_percentage', 0):.1f}%)")
            if clustering_metrics.get('total_clusters', 0) > 0:
                lines.append(f"   ‚Ä¢ –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞: {clustering_metrics.get('avg_cluster_size', 0):.1f}")
                lines.append(f"   ‚Ä¢ –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π –∫–ª–∞—Å—Ç–µ—Ä: {clustering_metrics.get('max_cluster_size', 0)} –Ω–æ–≤–æ—Å—Ç–µ–π")
                lines.append(f"   ‚Ä¢ –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –∫–ª–∞—Å—Ç–µ—Ä: {clustering_metrics.get('min_cluster_size', 0)} –Ω–æ–≤–æ—Å—Ç–µ–π")
            lines.append("")

        lines.append("")

        for idx, narrative in enumerate(narratives, 1):
            lines.append(f"–¢–ï–ú–ê #{idx} (–Ω–æ–≤–æ—Å—Ç–µ–π: {narrative['size']})")
            lines.append("-" * 60)
            lines.append(f"–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {', '.join(narrative['keywords'][:5])}")
            lines.append("")
            lines.append("–ü—Ä–∏–º–µ—Ä—ã –Ω–æ–≤–æ—Å—Ç–µ–π:")
            for news_item in narrative.get('news_examples', [])[:3]:
                lines.append(f"  –ó–∞–≥–æ–ª–æ–≤–æ–∫: {news_item['title']}")
                lines.append(f"  –ò—Å—Ç–æ—á–Ω–∏–∫: {news_item['source_name']}")
                lines.append(f"  –°—Å—ã–ª–∫–∞: {news_item['link']}")
                lines.append("")
        
        lines.append("=" * 60)
        
        return "\n".join(lines)
